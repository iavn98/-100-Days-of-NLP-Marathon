{"cells":[{"cell_type":"markdown","metadata":{"id":"gu_3NTX5jJPz"},"source":["### 作業目的: 熟練自定義collate_fn與sampler進行資料讀取\n","\n","本此作業主要會使用[IMDB](http://ai.stanford.edu/~amaas/data/sentiment/)資料集利用Pytorch的Dataset與DataLoader進行\n","客製化資料讀取。\n","下載後的資料有分成train與test，因為這份作業目的在讀取資料，所以我們取用train部分來進行練習。\n","(請同學先行至IMDB下載資料)"]},{"cell_type":"markdown","metadata":{"id":"wcriL3BRjJP1"},"source":["### 載入套件"]},{"cell_type":"code","source":["!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n","!tar -zxf aclImdb_v1.tar.gz"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lDiu8763kzLt","executionInfo":{"status":"ok","timestamp":1728717241253,"user_tz":-480,"elapsed":32230,"user":{"displayName":"Master Boxing","userId":"10326899279227255178"}},"outputId":"83749a19-bbbb-403b-dfa8-05fe29e05e14"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-10-12 07:13:29--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n","Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n","Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 84125825 (80M) [application/x-gzip]\n","Saving to: ‘aclImdb_v1.tar.gz’\n","\n","aclImdb_v1.tar.gz   100%[===================>]  80.23M  4.41MB/s    in 23s     \n","\n","2024-10-12 07:13:52 (3.43 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n","\n"]}]},{"cell_type":"code","execution_count":14,"metadata":{"id":"HN-0unmyjJP2","executionInfo":{"status":"ok","timestamp":1728717953123,"user_tz":-480,"elapsed":469,"user":{"displayName":"Master Boxing","userId":"10326899279227255178"}},"outputId":"79017f4d-6131-4e1a-8fbf-a7214c015f3e","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["# Import torch and other required modules\n","import nltk\n","nltk.download('stopwords')   # 下載stopwords\n","nltk.download('punkt')   # 下載word_tokenize需要的corpus\n","\n","import os\n","import re\n","import glob\n","import torch\n","import numpy as np\n","from nltk.corpus import stopwords\n","from torch.utils.data import Dataset, DataLoader, RandomSampler\n","from torch.nn.utils.rnn import pad_sequence"]},{"cell_type":"markdown","metadata":{"id":"dV8qZ5fFjJP4"},"source":["### 探索資料與資料前處理\n","這份作業我們使用test資料中的pos與neg\n"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"VCc2l0wDjJP5","outputId":"b06a2c57-fde1-4a2e-b268-658d40ebb148","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728717278430,"user_tz":-480,"elapsed":489,"user":{"displayName":"Master Boxing","userId":"10326899279227255178"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["vocab length before removing stopwords: 89527\n","vocab length after removing stopwords: 89356\n"]}],"source":["# 讀取字典，這份字典為review內所有出現的字詞\n","with open(os.path.join('aclImdb', 'imdb.vocab'), encoding='utf-8') as f:\n","    vocab = [line.strip() for line in f.readlines()]\n","\n","# 以nltk stopwords移除贅字，過多的贅字無法提供有用的訊息，也可能影響模型的訓練\n","print(f\"vocab length before removing stopwords: {len(vocab)}\")\n","en_stopwords = set(stopwords.words('english'))\n","vocab = [word for word in vocab if word not in en_stopwords]\n","print(f\"vocab length after removing stopwords: {len(vocab)}\")\n","\n","# 將字典轉換成dictionary\n","vocab_dic = {word: idx for idx, word in enumerate(vocab)}"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"3zuvpzkmjJP5","outputId":"c05a1e28-c5b0-48ca-c5c4-fc69702d961c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728717619136,"user_tz":-480,"elapsed":486,"user":{"displayName":"Master Boxing","userId":"10326899279227255178"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[('aclImdb/train/pos/8252_9.txt', 1), ('aclImdb/train/pos/3803_9.txt', 1)]\n","Total reviews: 25000\n"]}],"source":["# 將資料打包成(x, y)配對，其中x為review的檔案路徑，y為正評(1)或負評(0)\n","# 這裡將x以檔案路徑代表的原因是讓同學練習不一次將資料全讀取進來，若電腦記憶體夠大(所有資料檔案沒有很大)\n","# 可以將資料全一次讀取，可以減少在訓練時I/O時間，增加訓練速度\n","review_pairs = []\n","for folder, label in [('pos', 1), ('neg', 0)]:\n","    filepaths = glob.glob(os.path.join('aclImdb', 'train', folder, '*'))\n","    for filepath in filepaths:\n","        review_pairs.append((filepath, label))\n","\n","print(review_pairs[:2])\n","print(f\"Total reviews: {len(review_pairs)}\")"]},{"cell_type":"markdown","metadata":{"id":"olpq5DLUjJP5"},"source":["### 建立Dataset, DataLoader, Sampler與Collate_fn讀取資料\n","這裡我們會需要兩個helper functions，其中一個是讀取資料與清洗資料的函式(load_review)，另外一個是生成詞向量函式\n","(generate_vec)，注意這裡我們用來產生詞向量的方法是單純將文字tokenize(為了使產生的文本長度不同，而不使用BoW)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"i6paoYq2jJP6","executionInfo":{"status":"ok","timestamp":1728717840418,"user_tz":-480,"elapsed":10,"user":{"displayName":"Master Boxing","userId":"10326899279227255178"}}},"outputs":[],"source":["def load_review(review_path):\n","    with open(review_path, encoding='utf-8') as f:\n","        review = f.read()\n","\n","    # 移除non-alphabet符號、贅字與tokenize\n","    review = re.sub(r'\\W', ' ', review)\n","    review = nltk.word_tokenize(review)\n","\n","    return review\n","\n","def generate_vec(review, vocab_dic):\n","    idx_vec = [vocab_dic[word] for word in review if vocab_dic.get(word)]\n","\n","    return idx_vec"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"pFsIxdnEjJP6","executionInfo":{"status":"ok","timestamp":1728717875591,"user_tz":-480,"elapsed":457,"user":{"displayName":"Master Boxing","userId":"10326899279227255178"}}},"outputs":[],"source":["# 建立客製化dataset\n","class dataset(Dataset):\n","    '''custom dataset to load reviews and labels\n","    Parameters\n","    ----------\n","    data_pairs: list\n","        directory of all review-label pairs\n","    vocab: list\n","        list of vocabularies\n","    '''\n","    def __init__(self, data_dirs, vocab):\n","        self.data_dirs = data_dirs\n","        self.vocab = vocab\n","\n","    def __len__(self):\n","        return len(self.data_dirs)\n","\n","    def __getitem__(self, idx):\n","        review_path, label = self.data_dirs[idx]\n","        review = load_review(review_path)\n","        idx_vector = generate_vec(review, self.vocab)\n","\n","        return idx_vector, label\n","\n","\n","# 建立客製化collate_fn，將長度不一的文本pad 0變成相同長度\n","def collate_fn(batch):\n","    reviews, labels = zip(*batch)\n","    lengths = torch.LongTensor([len(review) for review in reviews])\n","    labels = torch.LongTensor(labels)\n","    reviews = pad_sequence([\n","        torch.LongTensor(review) for review in reviews\n","    ], batch_first=True, padding_value=0)\n","\n","    return reviews, labels, lengths"]},{"cell_type":"code","execution_count":15,"metadata":{"scrolled":true,"id":"kEoMIFgUjJP6","outputId":"69ed18d8-8f09-4565-fea6-4fba40ed2317","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728717958214,"user_tz":-480,"elapsed":479,"user":{"displayName":"Master Boxing","userId":"10326899279227255178"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[ 1211,   859,   583,  ...,   250,    44,   455],\n","         [12498,   725,    43,  ...,     0,     0,     0],\n","         [  306,    12,     2,  ...,     0,     0,     0],\n","         [ 5313,   839,    20,  ...,     0,     0,     0]]),\n"," tensor([0, 0, 0, 1]),\n"," tensor([334, 121,  46,  92]))"]},"metadata":{},"execution_count":15}],"source":["# 使用Pytorch的RandomSampler來進行indice讀取並建立dataloader\n","custom_dataset = dataset(review_pairs, vocab_dic)\n","custom_dataloader = DataLoader(custom_dataset,\n","                               batch_size=4,\n","                               sampler=RandomSampler(custom_dataset),\n","                               collate_fn=collate_fn\n",")\n","next(iter(custom_dataloader))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9JQH-fh1jJP6"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"cupoy_env","language":"python","name":"cupoy_env"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}